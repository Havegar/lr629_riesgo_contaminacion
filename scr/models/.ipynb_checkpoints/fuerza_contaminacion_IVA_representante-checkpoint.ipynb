{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "125e0088-3506-4daa-9fe3-0bef0914a0ea",
   "metadata": {},
   "source": [
    "## Apiux & SII: Fuerza entre entidades tributaria relacionada a probabilidad de contaminacion, definicion en base a IVA y contaminacion de representantes.\n",
    "## Henry Vega (henrry.vega@api-ux.com)\n",
    "## Data scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa417cd8-bf17-4bbb-b6eb-e65a9bd034d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "from pyspark_dist_explore import hist\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.types import StringType,TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44925030-d243-4d69-8b81-7a1130c485e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/30 20:32:51 WARN SparkConf: The configuration key 'spark.yarn.access.hadoopFileSystems' has been deprecated as of Spark 3.0 and may be removed in the future. Please use the new key 'spark.kerberos.access.hadoopFileSystems' instead.\n",
      "23/12/30 20:32:51 WARN SparkConf: The configuration key 'spark.yarn.access.hadoopFileSystems' has been deprecated as of Spark 3.0 and may be removed in the future. Please use the new key 'spark.kerberos.access.hadoopFileSystems' instead.\n",
      "Setting spark.hadoop.yarn.resourcemanager.principal to hvega.externo\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/30 20:32:51 WARN SparkConf: The configuration key 'spark.yarn.access.hadoopFileSystems' has been deprecated as of Spark 3.0 and may be removed in the future. Please use the new key 'spark.kerberos.access.hadoopFileSystems' instead.\n",
      "23/12/30 20:32:51 WARN SparkConf: The configuration key 'spark.yarn.access.hadoopFileSystems' has been deprecated as of Spark 3.0 and may be removed in the future. Please use the new key 'spark.kerberos.access.hadoopFileSystems' instead.\n",
      "23/12/30 20:32:51 WARN SparkConf: The configuration key 'spark.yarn.access.hadoopFileSystems' has been deprecated as of Spark 3.0 and may be removed in the future. Please use the new key 'spark.kerberos.access.hadoopFileSystems' instead.\n",
      "23/12/30 20:32:52 WARN JettyUtils: GET /jobs/ failed: java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:51)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:276)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:90)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:81)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:503)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:590)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:581)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:32:52 WARN HttpChannel: /jobs/\n",
      "java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:51)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:276)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:90)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:81)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:503)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:590)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:581)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:32:53 WARN JettyUtils: GET /jobs/ failed: java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:51)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:276)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:90)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:81)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:503)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:590)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:581)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n",
      "\tat org.sparkproject.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:32:53 WARN HttpChannel: /jobs/\n",
      "java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:51)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:276)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:90)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:81)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:503)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:590)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:581)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n",
      "\tat org.sparkproject.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:32:54 WARN HadoopFSDelegationTokenProvider: Token ABFS/IDBroker has not set up issue date properly. (provided: 0) Using current timestamp (1703968374726) as issue date instead. Consult token implementor to fix the behavior.\n",
      "23/12/30 20:32:54 WARN HadoopFSDelegationTokenProvider: Token ABFS/IDBroker has not set up issue date properly. (provided: 0) Using current timestamp (1703968374730) as issue date instead. Consult token implementor to fix the behavior.\n",
      "23/12/30 20:32:54 WARN JettyUtils: GET /jobs/ failed: java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:51)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:276)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:90)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:81)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:503)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:590)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:581)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n",
      "\tat org.sparkproject.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:32:54 WARN HttpChannel: /jobs/\n",
      "java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:51)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:276)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:90)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:81)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:503)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:590)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:581)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n",
      "\tat org.sparkproject.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:32:55 WARN HiveServer2CredentialProvider: Failed to get HS2 delegation token\n",
      "java.util.NoSuchElementException: spark.sql.hive.hiveserver2.jdbc.url\n",
      "\tat org.apache.spark.SparkConf.$anonfun$get$1(SparkConf.scala:245)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.SparkConf.get(SparkConf.scala:245)\n",
      "\tat com.hortonworks.spark.deploy.yarn.security.HiveServer2CredentialProvider.obtainDelegationTokens(HiveServer2CredentialProvider.scala:64)\n",
      "\tat org.apache.spark.deploy.security.HadoopDelegationTokenManager.$anonfun$obtainDelegationTokens$2(HadoopDelegationTokenManager.scala:164)\n",
      "\tat scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:245)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n",
      "\tat scala.collection.MapLike$DefaultValuesIterable.foreach(MapLike.scala:213)\n",
      "\tat scala.collection.TraversableLike.flatMap(TraversableLike.scala:245)\n",
      "\tat scala.collection.TraversableLike.flatMap$(TraversableLike.scala:242)\n",
      "\tat scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)\n",
      "\tat org.apache.spark.deploy.security.HadoopDelegationTokenManager.org$apache$spark$deploy$security$HadoopDelegationTokenManager$$obtainDelegationTokens(HadoopDelegationTokenManager.scala:162)\n",
      "\tat org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anon$4.run(HadoopDelegationTokenManager.scala:226)\n",
      "\tat org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anon$4.run(HadoopDelegationTokenManager.scala:224)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)\n",
      "\tat org.apache.spark.deploy.security.HadoopDelegationTokenManager.obtainTokensAndScheduleRenewal(HadoopDelegationTokenManager.scala:224)\n",
      "\tat org.apache.spark.deploy.security.HadoopDelegationTokenManager.org$apache$spark$deploy$security$HadoopDelegationTokenManager$$updateTokensTask(HadoopDelegationTokenManager.scala:198)\n",
      "\tat org.apache.spark.deploy.security.HadoopDelegationTokenManager.start(HadoopDelegationTokenManager.scala:123)\n",
      "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.$anonfun$start$1(CoarseGrainedSchedulerBackend.scala:552)\n",
      "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.$anonfun$start$1$adapted(CoarseGrainedSchedulerBackend.scala:549)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend.start(CoarseGrainedSchedulerBackend.scala:549)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.KubernetesClusterSchedulerBackend.start(KubernetesClusterSchedulerBackend.scala:95)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:220)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:581)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:32:55 WARN JettyUtils: GET /jobs/ failed: java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:51)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:276)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:90)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:81)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:503)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:590)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:581)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n",
      "\tat org.sparkproject.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:32:55 WARN HttpChannel: /jobs/\n",
      "java.util.NoSuchElementException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:51)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:276)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:90)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:81)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:503)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:590)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:581)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:380)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n",
      "\tat org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n",
      "\tat org.sparkproject.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:32:56 WARN ExecutorAllocationManager: Dynamic allocation without a shuffle service is an experimental feature.\n",
      "23/12/30 20:32:56 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-2\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-2, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-2\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:126)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:81)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:32:56 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-3\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-3, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-3\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$anon$2.run(ExecutorPodsSnapshotsStoreImpl.scala:158)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:32:57 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-4\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-4, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-4\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:126)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:81)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:32:58 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-5\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-5, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-5\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:126)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:81)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:32:59 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-6\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-6, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-6\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:126)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:81)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:33:00 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-7\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-7, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-7\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:126)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:81)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:33:02 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-8\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-8, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-8\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:126)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:81)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:33:03 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-9\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-9, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-9\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:126)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:81)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:33:04 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-10\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-10, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-10\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:126)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:81)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:33:05 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-11\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-11, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-11\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:126)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:81)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:33:06 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-12\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-12, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-12\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:126)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:81)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:33:07 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-13\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-13, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-13\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:126)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:81)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:33:08 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-15\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-15, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-15\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:126)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:81)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:33:09 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-16\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-16, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-16\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:126)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:81)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:33:10 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-17\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-17, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-17\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:126)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:81)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:33:11 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-18\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-18, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-18\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:126)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:81)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:33:12 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-19\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-19, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-19\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:126)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:81)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:33:13 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-20\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-20, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=object is being deleted: pods \"cdsw-g33muhmq3zwhp33k-exec-20\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:126)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:81)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/12/30 20:33:16 WARN ExecutorPodsSnapshotsStoreImpl: Exception when notifying snapshot subscriber.\n",
      "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.0.0.1/api/v1/namespaces/mlx-user-58/pods. Message: pods \"cdsw-g33muhmq3zwhp33k-exec-30\" already exists. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=null, kind=pods, name=cdsw-g33muhmq3zwhp33k-exec-30, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=pods \"cdsw-g33muhmq3zwhp33k-exec-30\" already exists, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=AlreadyExists, status=Failure, additionalProperties={}).\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:681)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:620)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:560)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:521)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:309)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:773)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:348)\n",
      "\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:88)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:420)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:402)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:366)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:351)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:351)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:129)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:138)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:126)\n",
      "\tat org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:81)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "  .appName(\"Test\")  \\\n",
    "  .config(\"spark.yarn.access.hadoopFileSystems\",\"abfs://data@datalakesii.dfs.core.windows.net/\") \\\n",
    "  .config(\"spark.executor.memory\", \"24g\") \\\n",
    "  .config(\"spark.driver.memory\", \"12g\")\\\n",
    "  .config(\"spark.executor.cores\", \"12\") \\\n",
    "  .config(\"spark.executor.instances\", \"24\") \\\n",
    "  .config(\"spark.driver.maxResultSize\", \"12g\") \\\n",
    "  .getOrCreate()\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "sc=spark.sparkContext\n",
    "sc.setLogLevel ('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb894c35-8e6c-4beb-b511-9536d37b0f55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hive Session ID = 5a71f30b-e5df-46a7-97af-8d77862699d1\n"
     ]
    }
   ],
   "source": [
    "df=spark.sql(\"select dhdr_rut_emisor,dhdr_rut_recep,dhdr_iva,dhdr_mnt_total,dhdr_fch_emis_int from dwbgdata.header_dte_consolidada_enc_sas_analitica where (dtdc_codigo ='33' or dtdc_codigo='34')\")\n",
    "df = df.withColumn(\"dhdr_fch_emis_int\", from_unixtime(unix_timestamp(col(\"dhdr_fch_emis_int\").cast(\"string\"),\"yyyyMMdd\"),\"yyyy-MM-dd HH:mm:ss\"))\n",
    "#df = df.withColumn(\"dhdr_fch_emis_int\",df[\"dhdr_fch_emis_int\"].cast(StringType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad75e941-e707-4c89-97e6-802e4ae9ce5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"comercial\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f699213a-0fbe-419d-bf90-e055e481a303",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(dhdr_rut_emisor,StringType,true),StructField(dhdr_rut_recep,StringType,true),StructField(dhdr_iva,LongType,true),StructField(dhdr_mnt_total,DecimalType(22,5),true),StructField(dhdr_fch_emis_int,StringType,true)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52cba31d-880d-4902-82f6-8b240bf82dd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#spark.sql(\"select count(*) from comercial\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ee7773-8b1a-4a8e-9cf1-546d103e31eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2=spark.sql(\"select REPR_FECHA_INICIO_VO, CONT_RUT,CONT_RUT_REPRESENTANTE,REPR_FECHA_TERMINO_VO from dw.dw_trn_representantes_eh \")\n",
    "df2.createOrReplaceTempView(\"representante\")\n",
    "#spark.sql(\" select count(*) from representante\").show()\n",
    "#df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f32b7a5b-47e1-4411-891f-2ee88c261edc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(REPR_FECHA_INICIO_VO,TimestampType,true),StructField(CONT_RUT,StringType,true),StructField(CONT_RUT_REPRESENTANTE,StringType,true),StructField(REPR_FECHA_TERMINO_VO,TimestampType,true)))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bea65941-5160-41c2-b1cb-14f375242195",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=spark.sql(\"select * from comercial left join representante on comercial.dhdr_rut_recep=representante.CONT_RUT \")\n",
    "a.createOrReplaceTempView(\"tabla\")\n",
    "#spark.sql(\" select count(*) from tabla\").show()\n",
    "\n",
    "#a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31886bac-2671-489f-a199-a19df6c75ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b=spark.sql(\"select * from tabla where tabla.CONT_RUT is not null\")\n",
    "b.createOrReplaceTempView(\"tabla\")\n",
    "#spark.sql(\" select count(*) from tabla\").show()\n",
    "#b.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae78e4dd-ccb0-4bea-acef-3a34ad81ada7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df3 = spark.read.options(header=True,inferSchema=True,delimiter=\",\").csv(\"data/processed/contaminados.csv\")\n",
    "df3.createOrReplaceTempView(\"contaminados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abcfa62a-4020-4546-bcc5-284db3272e91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"select * from tabla left join contaminados on tabla.CONT_RUT_REPRESENTANTE=contaminados.cont_rut\").createOrReplaceTempView(\"tabla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5eb4dfcc-c273-4a3c-978a-fdd5e448a034",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#spark.sql(\" select count(*) from tabla\").show()\n",
    "#spark.sql(\"select * from tabla\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fa48d10-a27f-477a-8069-66d010ed75c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"select dhdr_rut_emisor,dhdr_rut_recep,dhdr_iva,REPR_FECHA_INICIO_VO, dhdr_fch_emis_int,REPR_FECHA_TERMINO_VO,CONT_RUT_REPRESENTANTE,score from tabla where (dhdr_fch_emis_int>=REPR_FECHA_INICIO_VO) and (dhdr_fch_emis_int<=REPR_FECHA_TERMINO_VO or REPR_FECHA_TERMINO_VO is null) and dhdr_iva>0\").createOrReplaceTempView(\"tabla\")\n",
    "#spark.sql(\" select count(*) from tabla\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a688395-fbda-4d53-8388-4e3343f93aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select dhdr_rut_emisor,dhdr_rut_recep, count(*) as count1,sum(dhdr_iva) as sum1 from tabla where score is not null group by dhdr_rut_emisor,dhdr_rut_recep\").createOrReplaceTempView(\"aux2\")\n",
    "spark.sql(\"select dhdr_rut_emisor, dhdr_rut_recep, count(*) as count2,sum(dhdr_iva) as sum2 from tabla group by dhdr_rut_emisor,dhdr_rut_recep\").createOrReplaceTempView(\"aux1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7824618c-976c-4ca6-aa55-a23ff4263aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+------+\n",
      "|     dhdr_rut_emisor|      dhdr_rut_recep|count2|  sum2|\n",
      "+--------------------+--------------------+------+------+\n",
      "|P4hjpI0EdQaD5Qwrd...|+/+IMFryGSJkidvlc...|     8| 45186|\n",
      "|dwElNqcCQQiFyI3ic...|+/+IMFryGSJkidvlc...|     1|  3670|\n",
      "|PVFjiIt69vWZC2XGL...|+/+IMFryGSJkidvlc...|     6| 41382|\n",
      "|W+KgSjqyg0ruXJt6O...|+/+IMFryGSJkidvlc...|     2| 15966|\n",
      "|mB1kyvShd16kHgeEd...|+/+IMFryGSJkidvlc...|     1|  4260|\n",
      "|WS8UGIQ0bEY4+F6ZQ...|+/+IMFryGSJkidvlc...|     1| 26832|\n",
      "|OfOv6+ieOcqmCBoyJ...|+/+IMFryGSJkidvlc...|     1|   778|\n",
      "|tK7X+Q/ho2Fyh7clL...|+/+IMFryGSJkidvlc...|     1|  4306|\n",
      "|shRPyAsNITRHoPWgK...|+/+IMFryGSJkidvlc...|     2| 37621|\n",
      "|Y5pbdrxQ5HDvyRGv2...|+/+IMFryGSJkidvlc...|     1|  3321|\n",
      "|fNbGIovmthwhGeUH+...|+/+IMFryGSJkidvlc...|     1|  6066|\n",
      "|FynCjCaAj9E3eByLf...|+/+IMFryGSJkidvlc...|     1|  3800|\n",
      "|d1ud7RniwWMUFavFi...|+/+IMFryGSJkidvlc...|     1|   991|\n",
      "|4QwopbeTytMAQ1T/z...|+03yIiPxc4t3f47ON...|    33| 57804|\n",
      "|Adm7DEpaS7io2axZx...|+03yIiPxc4t3f47ON...|     3|107141|\n",
      "|OfOv6+ieOcqmCBoyJ...|+03yIiPxc4t3f47ON...|    17|125216|\n",
      "|9vElon9jEghUElY4f...|+03yIiPxc4t3f47ON...|     8| 52760|\n",
      "|EpdeOSpR+NqfHm9M/...|+03yIiPxc4t3f47ON...|     1|   715|\n",
      "|Pn1oFMN6vJsn1Lm2K...|+03yIiPxc4t3f47ON...|    15|184554|\n",
      "|lXK8ax4RldJC+/xgc...|+03yIiPxc4t3f47ON...|     1|  4167|\n",
      "+--------------------+--------------------+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from aux1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8baf081-e9c6-46be-9c7a-f88846b8e07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:>                                                         (0 + 1) / 1]]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+----+------+-------+\n",
      "|     dhdr_rut_emisor|      dhdr_rut_recep|count1|sum1|count2|   sum2|\n",
      "+--------------------+--------------------+------+----+------+-------+\n",
      "|+98GRovSqa7/HlB33...|++kwNysX7NuRMg7XO...|     0|   0|     2|1611200|\n",
      "|/0WJfI6VWgBQyOdpF...|+0wRZBQjNxBW1yId3...|     0|   0|     1|   4784|\n",
      "|/zviw20NHR1Vunwo/...|++CaFJK6l6FHIkQzd...|     0|   0|     1|  12118|\n",
      "|03s0A5AJ8soMrlSLE...|+0hbDxPpJhD5J4cmM...|     0|   0|     3|  28874|\n",
      "|1LuNfb/EedigHNhvO...|+/7DbRVkbRN/1wxN2...|     0|   0|     1|  22665|\n",
      "|1iYjiy0aM+c2MKvPH...|+/+b88HAubkiug11W...|     0|   0|   298|4331304|\n",
      "|1iYjiy0aM+c2MKvPH...|+3A9a70+/4q4Y6B6V...|     0|   0|    11| 108398|\n",
      "|25h7mudqMEixxNei2...|+/+b88HAubkiug11W...|     0|   0|    50| 476056|\n",
      "|2CBRm9pxJ0oc/gUdR...|+/087gJ2Y5n87Uotn...|     0|   0|     9| 171912|\n",
      "|2IUJpCOCUc3oDgrfV...|+0IpN6iICKxe6gzEp...|     0|   0|     4| 252510|\n",
      "|3FOfVSnoQS2hp3tbe...|+/JJJahnlkwlGco4I...|     0|   0|    26|  77260|\n",
      "|3TRSFJYppOvPqehD+...|++S1yR/YEwaqUh6kQ...|     0|   0|     4|1025620|\n",
      "|3kDoQB5psmvgUu/EI...|+/d9cpDe25pKPXt7x...|     0|   0|     2|1996900|\n",
      "|47oGu5juiHIYcKWSh...|++UzwrMtYcjxQWuCC...|     0|   0|   120| 785908|\n",
      "|4RvHrmkpG2fP4DQop...|+2uSl7r/Qbddr9hGJ...|     0|   0|     1|   2578|\n",
      "|66PwEReQr9BMi5lx/...|++dokFpF3k/ZvgKYk...|     0|   0|    16| 173628|\n",
      "|7ER3Cv21nUJLhMKX3...|+3Fb6sYyJ58kzYHvh...|     0|   0|     4|  75938|\n",
      "|7SG6Tl5kLh51IxWyw...|++bc7+qatVdXO3ptP...|     0|   0|     3|   2850|\n",
      "|84QM4DYxJsODMucIj...|+/3N6W4d+LRqCgoW2...|     0|   0|     4|  12844|\n",
      "|8Pvp3yMUcDg/CauZj...|++2DK/e8a0qWOS7QA...|     0|   0|     2|   9574|\n",
      "+--------------------+--------------------+------+----+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select aux1.dhdr_rut_emisor as dhdr_rut_emisor, aux1.dhdr_rut_recep as dhdr_rut_recep, CASE WHEN count1 is null then 0 else count1 end as count1, CASE WHEN sum1 is null then 0 else sum1 end as sum1, count2, sum2 from aux1 left join aux2 on (aux1.dhdr_rut_emisor=aux2.dhdr_rut_emisor and aux1.dhdr_rut_recep=aux2.dhdr_rut_recep)\").createOrReplaceTempView(\"tabla\")\n",
    "spark.sql(\"select * from tabla\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3738f58b-bbf9-414a-af20-049ca0143073",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:(738 + 264) / 3216][Stage 30:>  (0 + 0) / 83][Stage 31:>(0 + 0) / 3216]\r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select dhdr_rut_emisor,dhdr_rut_recep,count1/count2 as Fa, sum1/sum2 as Fb from tabla\").createOrReplaceTempView(\"tabla\")\n",
    "spark.sql(\"SELECT *  from tabla\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef73f35-830a-4727-a271-2de2819c43f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"select dhdr_rut_emisor,dhdr_rut_recep, round(Fa/2+Fb/2,5) as Fuerza from tabla\").createOrReplaceTempView(\"fuerza\")\n",
    "spark.sql(\"select dhdr_rut_emisor as emisor,dhdr_rut_recep as receptor, Fuerza as Fi  from fuerza \").createOrReplaceTempView(\"fuerza\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4862379e-84e2-4aa3-b072-eef41d68df03",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT *  from fuerza order by Fi asc\").show() \n",
    "spark.sql(\"SELECT *  from fuerza order by Fi desc\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedce9bf-7371-4bcc-b41f-dd5591f24dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "representante=spark.sql(\"select *  from fuerza\").toPandas()\n",
    "representante.to_csv('data/processed/fuerza_IVA_representante.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7659e19e-4e8f-41dc-bfcb-d4463817854d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2031f18-c13c-4d63-ae7e-ffe08df98e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
